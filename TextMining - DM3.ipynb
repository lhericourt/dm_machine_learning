{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import des différents package\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0.\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Question 1\n",
    "###############################################################################\n",
    "\n",
    "# Fonction qui renvoie le dictionnaire et la matrice\n",
    "# qui indique pour chaque mot le nombre d'occurences\n",
    "# dans chaque texte\n",
    "# Pour anticiper les questions suivantes, des paramètre facultatifs\n",
    "# ont été ajoutés :\n",
    "#   - pour ne pas prendre en compte certains mots\n",
    "#   - pour utiliser les racines des mots\n",
    "def count_words(texts, english_stop=[], steeming=False):\n",
    "    words = set()\n",
    "\n",
    "    # On ne récupére les mots qui sont des \"vrais mots\"\n",
    "    # i.e. sans caractères spéciaux\n",
    "    for text in texts:\n",
    "        words_only = re.findall(r\"\\w+\", text)\n",
    "        if (not steeming):\n",
    "            [words.add(x) for x in words_only if not (x in english_stop)]\n",
    "        else:\n",
    "            stemmer = SnowballStemmer(\"english\")\n",
    "            [words.add(stemmer.stem(x)) for x in words_only if not (x in english_stop)]\n",
    "\n",
    "    vocabulary = dict()\n",
    "    for i, word in enumerate(words):\n",
    "        vocabulary[word] = i\n",
    "\n",
    "    n_features = len(vocabulary)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "\n",
    "    # On construit la matrice counts en comptant pour\n",
    "    # chaque mot de chaque texte son nombre d'occurences\n",
    "    for i in range(len(texts)):\n",
    "        words_only = re.findall(r\"\\w+\", texts[i])\n",
    "        for word in words_only:\n",
    "            if (steeming):\n",
    "                word = stemmer.stem(word)\n",
    "            if not (word in english_stop):\n",
    "                counts[i, vocabulary[word]] += 1\n",
    "\n",
    "    return vocabulary, counts\n",
    "\n",
    "vocabulary, X = count_words(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Question 2\n",
    "###############################################################################\n",
    "\n",
    "# Les critiques sont à la base issues d'une page HTML, avec différents types de notation \n",
    "# (via des étoiles, une note sur 10, la désignation d'une lettre...)\n",
    "# Pour chaque critique ils ont identifié un système de notion, puis si la note était bonne\n",
    "# la critique a été considérée comme positive, par contre si la note a été mauvaise la critique\n",
    "# a été considérée comme négative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Question 3\n",
    "###############################################################################\n",
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        self.T = [0, 0]\n",
    "        self.prior = [0, 0]\n",
    "        self.total_words = [0, 0]\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # On calcule le ratio des textes postifs et négatifs\n",
    "        self.prior[0] = len(texts_neg) / len(texts)\n",
    "        self.prior[1] = len(texts_pos) / len(texts)\n",
    "        \n",
    "        # On compte le nombre de mots pour chaque classe\n",
    "        # Sans oublier d'ajouter +1 par mot\n",
    "        self.total_words = [0, 0]\n",
    "        self.total_words[0] = np.sum(X[np.where(y == 0)]) + len(vocabulary)\n",
    "        self.total_words[1] = np.sum(X[np.where(y == 1)]) + len(vocabulary)\n",
    "        \n",
    "        # On calcule pour chaque mot sa fréquence dans chaque classe\n",
    "        self.T[0] = (np.sum(X[np.where(y == 0)], axis=0) + 1) / self.total_words[0]\n",
    "        self.T[1] = (np.sum(X[np.where(y == 1)], axis=0) + 1) / self.total_words[1]\n",
    "        return self\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        score = np.zeros(len(X))\n",
    "        proba = [0, 0]\n",
    "        for i, doc in enumerate(X):\n",
    "            # On calcule pour chaque classe le score du document\n",
    "            # A la différence de l'algorithme proposé je conserve\n",
    "            # les doublons de mots\n",
    "            for c in [0, 1]:\n",
    "                temp = doc * self.T[c]\n",
    "                temp = temp[np.where(temp > 0)]\n",
    "                proba[c] = sum(np.log(temp)) + math.log(self.prior[c])\n",
    "            # On sélectionne le score le plus élévé\n",
    "            if (proba[0] > proba[1]):\n",
    "                score[i] = 0\n",
    "            else:\n",
    "                score[i] = 1\n",
    "        return score\n",
    "      \n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bons résultats est : 82.20 %\n"
     ]
    }
   ],
   "source": [
    "nb = NB()\n",
    "nb.fit(X, y)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats est : {0:.2f} %\".format(100*nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bons résultats pour le modèle 0 est de : 78.50 %\n",
      "Le pourcentage de bons résultats pour le modèle 1 est de : 82.00 %\n",
      "Le pourcentage de bons résultats pour le modèle 2 est de : 79.50 %\n",
      "Le pourcentage de bons résultats pour le modèle 3 est de : 85.00 %\n",
      "Le pourcentage de bons résultats pour le modèle 4 est de : 79.50 %\n",
      "*******************************************************\n",
      "le pourcentage moyen de bons résultats est de : 80.90 %\n",
      "*******************************************************\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Question 4\n",
    "###############################################################################\n",
    "# La valeur choisie pour K doit être un diviseur du nombre de sample\n",
    "# Pour que le reste de l'algorithme fonctionne\n",
    "K = 5\n",
    "\n",
    "# Définition des données de training et de test\n",
    "X_train_K = [0] * K\n",
    "y_train_K = [0] * K\n",
    "X_test_K = [0] * K\n",
    "y_test_K = [0] * K\n",
    "\n",
    "error_K = [0] * K\n",
    "list_models = [0] * K\n",
    "\n",
    "\n",
    "# Alimentation des données de training et de test\n",
    "# à partir de X et y\n",
    "for i in range(K):\n",
    "    value_K = list(range(K))\n",
    "    value_K.remove(i)\n",
    "    \n",
    "    # Alimentation des données de test\n",
    "    X_test_K[i] = X[i::K]\n",
    "    y_test_K[i] = y[i::K]\n",
    "    \n",
    "    # Alimentation des données de training\n",
    "    for j in value_K:\n",
    "        if (type(X_train_K[i]) == int) :\n",
    "            X_train_K[i] = X[j::K]\n",
    "            y_train_K[i] = y[j::K]\n",
    "        else:\n",
    "            X_train_K[i] = np.append(X_train_K[i], X[j::K], axis=0)\n",
    "            y_train_K[i] = np.append(y_train_K[i], y[j::K], axis=0)\n",
    "\n",
    "            \n",
    "# Entrainement du modèle sur chaque données de training\n",
    "# Puis calcul de l'erreur sur les données de tests respectives\n",
    "for i in range(K):\n",
    "    nb = NB()\n",
    "    list_models[i] = nb\n",
    "    nb.fit(X_train_K[i], y_train_K[i])\n",
    "    error_K[i] = np.mean(np.abs(nb.predict(X_test_K[i]) - y_test_K[i]))\n",
    "    print(\"Le pourcentage de bons résultats pour le modèle {0} est de : {1:.2f} %\".format(i, 100*(1 - error_K[i])))\n",
    "\n",
    "print('*******************************************************')\n",
    "print(\"le pourcentage moyen de bons résultats est de : {0:.2f} %\".format(100*(1 - np.mean(error_K))))\n",
    "print('*******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bons résultats est : 82.70 %\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Question 5\n",
    "###############################################################################\n",
    "\n",
    "# Constitution du dictionnaire des mots à ignorer\n",
    "filenames_stop = sorted(glob(op.join('data', '*.stop')))\n",
    "words_stop = [open(f).read() for f in filenames_stop]\n",
    "words_stop = words_stop[0].split(\"\\n\")\n",
    "\n",
    "# Génération de la matrice de fréquence des mots en prenant\n",
    "# en compte les mots à ignorer\n",
    "vocabulary, X = count_words(texts, words_stop)\n",
    "\n",
    "# \n",
    "nb = NB()\n",
    "nb.fit(X, y)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats est : {0:.2f} %\".format(100*nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Le résultat s'est donc amélioré de 0.5 % par rapport à la question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le résulat pour la métode \"Sans aucune customisation\" est de : 81.30 %\n",
      " Le résulat pour la métode \"Avec la regex \\w+ pour supprimer les caractères spéciaux\" est de : 81.00 %\n",
      " Le résulat pour la métode \"En supprimant les stop words\" est de : 80.70 %\n",
      " Le résulat pour la métode \"En utilisant les pondérations par l'inverse de la fréquence \" est de : 80.00 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 2\" est de : 68.10 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 5\" est de : 82.40 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 10\" est de : 82.60 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 2\" est de : 68.10 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 5\" est de : 83.10 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 10\" est de : 84.20 %\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# scikitlearn - Question 1\n",
    "###############################################################################\n",
    "\n",
    "# Définition des libellés correspondant aux différentes méthodes\n",
    "# utilisées pour afficher dans le message de résultat\n",
    "method_used = [\n",
    "    \"Sans aucune customisation\",\n",
    "    \"Avec la regex \\w+ pour supprimer les caractères spéciaux\",\n",
    "    \"En supprimant les stop words\",\n",
    "    \"En utilisant les pondérations par l'inverse de la fréquence \",\n",
    "    \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 2\",\n",
    "    \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 5\",\n",
    "    \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 10\",\n",
    "    \" En utilisant l'analyse 'char' avec un  ngram_range de 2\",\n",
    "    \" En utilisant l'analyse 'char' avec un  ngram_range de 5\",\n",
    "    \" En utilisant l'analyse 'char' avec un  ngram_range de 10\",\n",
    "]\n",
    "\n",
    "# Définition de la liste des pipeline, un pipeline correspondant \n",
    "# à une méthode\n",
    "pipeline = [0] * len(method_used)\n",
    "\n",
    "pipeline[0] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[1] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='word', token_pattern=\"\\\\w+\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[2] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[3] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('tf_idf', TfidfTransformer()),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[4] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[5] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[6] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[7] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[8] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "pipeline[9] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', MultinomialNB())])\n",
    "\n",
    "# Calcul du résultat pour chaque Pipeline\n",
    "for i in range(len(pipeline)):\n",
    "    pipeline[i].fit(texts[::2], y[::2])\n",
    "    y_predi = pipeline[i].predict(texts[1::2])\n",
    "    print(\"\"\" Le résulat pour la métode \"{0}\" est de : {1:.2f} %\"\"\".format(method_used[i], 100*np.mean(y_predi == y[1::2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que la méthode de base a un score légèrement inférieur à celui obtenu par programmation manuelle. Cela peut venir soit du fait que le dictionnaire produit est légèrement différent, soit du fait que les mots en doublons dans un texte à analyser ne sont compter qu'une fois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un score meilleur en utilisant l'option 'char_wb' avec des groupes de lettres faisant au moins 5 caractères. Cette façon de faire est probablement meilleure car cela permet d'agréger des mots ayant des racines communes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'option 'char' donne un bon score avec des groupes de lettres faisant de 5 à 10 caractères, car cette option permet au final de prendre en compte l'ordonnancement des mots qui peut avoir un impact sur le sens du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le résulat pour la métode \"Sans aucune customisation\" est de : 0.83 %\n",
      " Le résulat pour la métode \"Avec la regex \\w+ pour supprimer les caractères spéciaux\" est de : 0.84 %\n",
      " Le résulat pour la métode \"En supprimant les stop words\" est de : 0.83 %\n",
      " Le résulat pour la métode \"En utilisant les pondérations par l'inverse de la fréquence \" est de : 0.80 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 2\" est de : 0.66 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 5\" est de : 0.84 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 10\" est de : 0.84 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 2\" est de : 0.82 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 5\" est de : 0.84 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 10\" est de : 0.84 %\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# scikitlearn - Question 2\n",
    "###############################################################################\n",
    "\n",
    "# Nous répétons la même méthodologie que précédemment\n",
    "# mais avec comme classifier la régression logistique\n",
    "\n",
    "pipeline[0] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[1] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='word', token_pattern=\"\\\\w+\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[2] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[3] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('tf_idf', TfidfTransformer()),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[4] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[5] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[6] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[7] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[7] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "pipeline[8] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', LogisticRegression())])\n",
    "\n",
    "for i in range(len(pipeline)):\n",
    "    pipeline[i].fit(texts[::2], y[::2])\n",
    "    y_predi = pipeline[i].predict(texts[1::2])\n",
    "    print(\"\"\" Le résulat pour la métode \"{0}\" est de : {1:.2f} %\"\"\".format(method_used[i], np.mean(y_predi == y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En règle général on constate que le classifieur de régression logistique donne de meilleur résulats que le classifieur Naive Bayes pour ce cas de classification (il n'y a que le dernier résultat qui est légèrement moins bon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le résulat pour la métode \"Sans aucune customisation\" est de : 0.81 %\n",
      " Le résulat pour la métode \"Avec la regex \\w+ pour supprimer les caractères spéciaux\" est de : 0.82 %\n",
      " Le résulat pour la métode \"En supprimant les stop words\" est de : 0.83 %\n",
      " Le résulat pour la métode \"En utilisant les pondérations par l'inverse de la fréquence \" est de : 0.65 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 2\" est de : 0.83 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 5\" est de : 0.83 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char_wb' avec un  ngram_range de 10\" est de : 0.66 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 2\" est de : 0.83 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 5\" est de : 0.84 %\n",
      " Le résulat pour la métode \" En utilisant l'analyse 'char' avec un  ngram_range de 10\" est de : 0.84 %\n"
     ]
    }
   ],
   "source": [
    "# Regression linear SVC\n",
    "pipeline[0] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[1] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[2] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(stop_words=\"english\")),\n",
    "    ('tf_idf', TfidfTransformer()),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[3] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[4] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[5] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char_wb\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[6] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(2, 2), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[7] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(5, 5), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "pipeline[8] = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer=\"char\", ngram_range=(10, 10), stop_words=\"english\")),\n",
    "    ('classifier', LinearSVC())])\n",
    "\n",
    "for i in range(len(pipeline)):\n",
    "    pipeline[i].fit(texts[::2], y[::2])\n",
    "    y_predi = pipeline[i].predict(texts[1::2])\n",
    "    print(\"\"\" Le résulat pour la métode \"{0}\" est de : {1:.2f} %\"\"\".format(method_used[i], np.mean(y_predi == y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En règle général on constate que le classifieur LinearSVC donne à peu près les mêmes résultats que le classifieur Naive Bayes pour ce cas là"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bons résultats avec racinisation est de : 0.827\n",
      "Le pourcentage de bons résultats avec words_stop et racinisation est de : 0.829\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# scikitlearn - Question 3\n",
    "###############################################################################\n",
    "\n",
    "# Calcul de la matrice X des fréquences des mots en\n",
    "# activant la fonctionnalité de stemming\n",
    "vocabulary, X = count_words(texts, stemming=True)\n",
    "nb = NB()\n",
    "nb.fit(X, y)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats avec racinisation est de : {}\".format(nb.score(X[1::2], y[1::2])))\n",
    "\n",
    "# On convertit le dictionnaire des stop en ne conservant que les racines\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "words_stop_stemmer = set(map(lambda x : stemmer.stem(x), words_stop))\n",
    "\n",
    "vocabulary, X = count_words(texts, english_stop=list(words_stop_stemmer), stemming=True)\n",
    "nb = NB()\n",
    "nb.fit(X, y)\n",
    "nb.fit(X[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats avec words_stop et racinisation est de : {0:.2f} %\".format(nb.score(X[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On constate que la racinisation des mots améliore quelque peu le résultat:\n",
    "- +0.5% pour le cas nominal\n",
    "- +0.2% pour le cas en prenant en compte les stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela semble logique puisque les mots de même racine vont être regroupés en un seul mot, et ainsi le poids de ces derniers ne seront pas dispersés en fonction de l'orthographe et de la forme des mots (exemple : \"dog\" et \"dogs\" seront regroupés dans l'unique mot \"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le pourcentage de bons résultats en supprimant des catégories de mots est de : 82.30 %\n",
      "Le pourcentage de bons résultats avec words_stop et en supprimant des catégories de mots est de : 81.70 %\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# scikitlearn - Question 4\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Fonction qui supprime de la matrice les colonnes qui\n",
    "# ne sont ni des noms, verbes, adjectifs ou adverbes\n",
    "def remove_types_of_words (X):\n",
    "    # Calcul des indices des mots à supprimer\n",
    "    index_to_delete = list()\n",
    "    for word, index in vocabulary.items():\n",
    "        word_token = word_tokenize(word)\n",
    "        if not (pos_tag(word_token)[0][1] in ('NN', 'VBZ', 'RB','JJ')):\n",
    "            index_to_delete.append(index)\n",
    "\n",
    "    # Réduction de la matrice X initiale en supprimant\n",
    "    # les colonnes issues du traitement précédent \n",
    "    X_reduce = np.delete(X, index_to_delete, axis=1)\n",
    "    \n",
    "    return X_reduce\n",
    "\n",
    "    \n",
    "# Calcul du résultat en supprimant les mots qui ne sont pas du\n",
    "# type désiré\n",
    "vocabulary, X = count_words(texts)\n",
    "X_reduce = remove_types_of_words(X)\n",
    "nb = NB()\n",
    "nb.fit(X_reduce, y)\n",
    "nb.fit(X_reduce[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats en supprimant des catégories de mots est de : {0:.2f} %\".format(100*nb.score(X_reduce[1::2], y[1::2])))\n",
    "\n",
    "\n",
    "# Calcul du résultat en supprimant les mots qui ne sont pas du\n",
    "# type désiré et que ne sont pas des stop words\n",
    "vocabulary, X = count_words(texts, english_stop=words_stop)\n",
    "X_reduce = remove_types_of_words(X)\n",
    "nb = NB()\n",
    "nb.fit(X_reduce, y)\n",
    "nb.fit(X_reduce[::2], y[::2])\n",
    "print(\"Le pourcentage de bons résultats avec words_stop et en supprimant des catégories de mots est de : {0:.2f} %\".format(100*nb.score(X_reduce[1::2], y[1::2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En supprimant les mots qui ne sont ni des verbes, ni des noms communs, ni des adjectifs, ni des adverbes on améliore le score de 0.1%\n",
    "On n'aurait pu pensé que le score aurait été un peu plus amélioré.\n",
    "De plus lorsque l'on supprime les stop words le score est dégradé. Certains des stop words doivent donc en fait avoir une signification utile pour le modèle."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
